{"cells":[{"cell_type":"markdown","metadata":{},"source":["# EMPOYEES DATA ANALYSIS USING PYSPARK"]},{"cell_type":"code","execution_count":null,"id":"392d8153-3ffa-465e-8b3a-30e13d23f4d9","metadata":{},"outputs":[],"source":["# Installing required packages  \n","\n","!pip install pyspark  findspark wget\n"]},{"cell_type":"code","execution_count":2,"id":"088cd3d3-1448-46d8-8f2c-87b4a4bca80f","metadata":{},"outputs":[],"source":["import findspark\n","\n","findspark.init()"]},{"cell_type":"code","execution_count":3,"id":"d6de71f1-649c-46fb-85e8-96793afd536d","metadata":{},"outputs":[],"source":["# PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the SparkContext.   \n","\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":4,"id":"2303fb3e-996b-4288-8d3d-a36af1d672e8","metadata":{},"outputs":[],"source":["# Creating a SparkContext object  \n","\n","sc = SparkContext.getOrCreate()\n","\n","# Creating a SparkSession  \n","\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Employee Data Analysis\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()"]},{"cell_type":"markdown","id":"ed0ddc14-eb9b-44cd-a7d3-0fdfc78c99d8","metadata":{},"source":["#### Generate a Spark DataFrame from the CSV data\n","\n","Read data from the provided CSV file, `employees.csv` and import it into a Spark DataFrame variable named `employees_df`.\n","\n"," \n"]},{"cell_type":"code","execution_count":6,"id":"d30e0f10-2d9e-4661-a0b9-89556592c311","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+---------+------+---+----------+\n","|Emp_No| Emp_Name|Salary|Age|Department|\n","+------+---------+------+---+----------+\n","|   198|   Donald|  2600| 29|        IT|\n","|   199|  Douglas|  2600| 34|     Sales|\n","|   200| Jennifer|  4400| 36| Marketing|\n","|   201|  Michael| 13000| 32|        IT|\n","|   202|      Pat|  6000| 39|        HR|\n","|   203|    Susan|  6500| 36| Marketing|\n","|   204|  Hermann| 10000| 29|   Finance|\n","|   205|  Shelley| 12008| 33|   Finance|\n","|   206|  William|  8300| 37|        IT|\n","|   100|   Steven| 24000| 39|        IT|\n","|   101|    Neena| 17000| 27|     Sales|\n","|   102|      Lex| 17000| 37| Marketing|\n","|   103|Alexander|  9000| 39| Marketing|\n","|   104|    Bruce|  6000| 38|        IT|\n","|   105|    David|  4800| 39|        IT|\n","|   106|    Valli|  4800| 38|     Sales|\n","|   107|    Diana|  4200| 35|     Sales|\n","|   108|    Nancy| 12008| 28|     Sales|\n","|   109|   Daniel|  9000| 35|        HR|\n","|   110|     John|  8200| 31| Marketing|\n","+------+---------+------+---+----------+\n","only showing top 20 rows\n","\n"]}],"source":["# Read data from the \"emp\" CSV file and import it into a DataFrame variable named \"employees_df\"  \n","\n","employees_df=spark.read.csv('employees.csv',header=True)\n","employees_df.show()"]},{"cell_type":"markdown","id":"78e2aa31-92fb-4bfd-9c8d-541284c3fd2f","metadata":{},"source":["#### Define a schema for the data\n","\n","Construct a schema for the input data and then utilize the defined schema to read the CSV file to create a DataFrame named `employees_df`.  \n"]},{"cell_type":"code","execution_count":7,"id":"f90a1d9d-adca-4a94-8753-db071994cc65","metadata":{},"outputs":[],"source":["# Define a Schema for the input data and read the file using the user-defined Schema\n","# Define the schema\n","schema = StructType([\n","    StructField(\"Emp_No\", IntegerType(), False),\n","    StructField(\"Emp_Name\", StringType(), True),\n","    StructField(\"Salary\", DoubleType(), True),\n","    StructField(\"Age\", IntegerType(), True),\n","    StructField(\"Department\", StringType(), True)\n","])\n","\n","employees_df=spark.read.csv('employees.csv',schema=schema,header=True)\n"]},{"cell_type":"markdown","id":"4c53e16a-4794-4893-8ee6-5a65fff480d1","metadata":{},"source":["#### Display schema of DataFrame\n","\n","Display the schema of the `employees_df` DataFrame, showing all columns and their respective data types.  \n"]},{"cell_type":"code","execution_count":8,"id":"a43700dc-b44c-4937-9729-a8a81f7f4462","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Emp_No: integer (nullable = true)\n"," |-- Emp_Name: string (nullable = true)\n"," |-- Salary: double (nullable = true)\n"," |-- Age: integer (nullable = true)\n"," |-- Department: string (nullable = true)\n","\n"]}],"source":["# Display all columns of the DataFrame, along with their respective data types\n","\n","employees_df.printSchema()"]},{"cell_type":"markdown","id":"7c5f2121-b0fc-4b98-bac3-8a4fa845bc8b","metadata":{},"source":["#### Create a temporary view\n","\n","Create a temporary view named `employees` for the `employees_df` DataFrame, enabling Spark SQL queries on the data. \n"]},{"cell_type":"code","execution_count":9,"id":"99bdefe6-e545-4076-92fe-fa46b69a779b","metadata":{},"outputs":[],"source":["# Create a temporary view named \"employees\" for the DataFrame\n","employees_df.createOrReplaceTempView('employees')\n"]},{"cell_type":"markdown","id":"723dbbb6-9c3b-4804-9168-2c5431ff4465","metadata":{},"source":["#### Execute an SQL query\n","\n","Compose and execute an SQL query to fetch the records from the `employees` view where the age of employees exceeds 30. Then, display the result of the SQL query, showcasing the filtered records.\n"]},{"cell_type":"code","execution_count":10,"id":"4a15fce1-b8f8-434b-bd91-7a623f57b5e8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+-----------+-------+---+----------+\n","|Emp_No|   Emp_Name| Salary|Age|Department|\n","+------+-----------+-------+---+----------+\n","|   199|    Douglas| 2600.0| 34|     Sales|\n","|   200|   Jennifer| 4400.0| 36| Marketing|\n","|   201|    Michael|13000.0| 32|        IT|\n","|   202|        Pat| 6000.0| 39|        HR|\n","|   203|      Susan| 6500.0| 36| Marketing|\n","|   205|    Shelley|12008.0| 33|   Finance|\n","|   206|    William| 8300.0| 37|        IT|\n","|   100|     Steven|24000.0| 39|        IT|\n","|   102|        Lex|17000.0| 37| Marketing|\n","|   103|  Alexander| 9000.0| 39| Marketing|\n","|   104|      Bruce| 6000.0| 38|        IT|\n","|   105|      David| 4800.0| 39|        IT|\n","|   106|      Valli| 4800.0| 38|     Sales|\n","|   107|      Diana| 4200.0| 35|     Sales|\n","|   109|     Daniel| 9000.0| 35|        HR|\n","|   110|       John| 8200.0| 31| Marketing|\n","|   111|     Ismael| 7700.0| 32|        IT|\n","|   112|Jose Manuel| 7800.0| 34|        HR|\n","|   113|       Luis| 6900.0| 34|     Sales|\n","|   116|     Shelli| 2900.0| 37|   Finance|\n","+------+-----------+-------+---+----------+\n","only showing top 20 rows\n","\n"]}],"source":["# SQL query to fetch solely the records from the View where the age exceeds 30\n","\n","spark.sql('SELECT * FROM Employees WHERE age > 30;').show()\n"]},{"cell_type":"markdown","id":"3ddf8ff1-6403-4352-a69f-df31a3a3ebd1","metadata":{},"source":["#### Calculate Average Salary by Department\n","\n","Compose an SQL query to retrieve the average salary of employees grouped by department. Display the result.\n"]},{"cell_type":"code","execution_count":12,"id":"615ceefc-381a-4f9c-9dbc-988712e9a3ef","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+-----------------+\n","|Department|       avg_salary|\n","+----------+-----------------+\n","|     Sales|5492.923076923077|\n","|        HR|           5837.5|\n","|   Finance|           5730.8|\n","| Marketing|6633.333333333333|\n","|        IT|           7400.0|\n","+----------+-----------------+\n","\n"]}],"source":["# SQL query to calculate the average salary of employees grouped by department\n","spark.sql('SELECT Department,AVG(salary) as avg_salary FROM Employees GROUP BY Department').show()"]},{"cell_type":"markdown","id":"32406372-6ebe-45c5-ac3a-e055b419d49a","metadata":{},"source":["#### Filter and Display IT Department Employees\n","\n","Apply a filter on the `employees_df` DataFrame to select records where the department is `'IT'`. Display the filtered DataFrame.\n"]},{"cell_type":"code","execution_count":18,"id":"1e07702f-7067-4897-99c1-41035ffe80ac","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+--------+-------+---+----------+\n","|Emp_No|Emp_Name| Salary|Age|Department|\n","+------+--------+-------+---+----------+\n","|   198|  Donald| 2600.0| 29|        IT|\n","|   201| Michael|13000.0| 32|        IT|\n","|   206| William| 8300.0| 37|        IT|\n","|   100|  Steven|24000.0| 39|        IT|\n","|   104|   Bruce| 6000.0| 38|        IT|\n","|   105|   David| 4800.0| 39|        IT|\n","|   111|  Ismael| 7700.0| 32|        IT|\n","|   129|   Laura| 3300.0| 38|        IT|\n","|   132|      TJ| 2100.0| 34|        IT|\n","|   136|   Hazel| 2200.0| 29|        IT|\n","+------+--------+-------+---+----------+\n","\n"]}],"source":["# Apply a filter to select records where the department is 'IT'\n","\n","employees_df.filter(employees_df.Department=='IT').show()"]},{"cell_type":"markdown","id":"219192ee-5ee6-41bb-a840-008fc139fe39","metadata":{},"source":["####  Add 10% Bonus to Salaries\n","\n","Perform a transformation to add a new column named \"SalaryAfterBonus\" to the DataFrame. Calculate the new salary by adding a 10% bonus to each employee's salary.\n"]},{"cell_type":"code","execution_count":21,"id":"6bd270b0-b428-46a7-a783-933f3071d69d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+---------+-------+---+----------+----------------+\n","|Emp_No| Emp_Name| Salary|Age|Department|SalaryAfterBonus|\n","+------+---------+-------+---+----------+----------------+\n","|   198|   Donald| 2600.0| 29|        IT|          2860.0|\n","|   199|  Douglas| 2600.0| 34|     Sales|          2860.0|\n","|   200| Jennifer| 4400.0| 36| Marketing|          4840.0|\n","|   201|  Michael|13000.0| 32|        IT|         14300.0|\n","|   202|      Pat| 6000.0| 39|        HR|          6600.0|\n","|   203|    Susan| 6500.0| 36| Marketing|          7150.0|\n","|   204|  Hermann|10000.0| 29|   Finance|         11000.0|\n","|   205|  Shelley|12008.0| 33|   Finance|         13208.8|\n","|   206|  William| 8300.0| 37|        IT|          9130.0|\n","|   100|   Steven|24000.0| 39|        IT|         26400.0|\n","|   101|    Neena|17000.0| 27|     Sales|         18700.0|\n","|   102|      Lex|17000.0| 37| Marketing|         18700.0|\n","|   103|Alexander| 9000.0| 39| Marketing|          9900.0|\n","|   104|    Bruce| 6000.0| 38|        IT|          6600.0|\n","|   105|    David| 4800.0| 39|        IT|          5280.0|\n","|   106|    Valli| 4800.0| 38|     Sales|          5280.0|\n","|   107|    Diana| 4200.0| 35|     Sales|          4620.0|\n","|   108|    Nancy|12008.0| 28|     Sales|         13208.8|\n","|   109|   Daniel| 9000.0| 35|        HR|          9900.0|\n","|   110|     John| 8200.0| 31| Marketing|          9020.0|\n","+------+---------+-------+---+----------+----------------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql.functions import col\n","\n","# Add a new column \"SalaryAfterBonus\" with 10% bonus added to the original salary\n","employees_df=employees_df.withColumn('SalaryAfterBonus',col('salary')+(col('salary')*0.10))\n","employees_df.show()\n"]},{"cell_type":"markdown","id":"518dac1e-e0de-4ac7-83a2-dc2ebbd010de","metadata":{},"source":["#### Find Maximum Salary by Age\n","\n","Group the data by age and calculate the maximum salary for each age group. Display the result.\n"]},{"cell_type":"code","execution_count":23,"id":"dec0faf6-d988-4517-99f6-904e79de66bd","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+\n","|age|Max_Salary|\n","+---+----------+\n","| 31|    8200.0|\n","| 34|    7800.0|\n","| 28|   12008.0|\n","| 27|   17000.0|\n","| 26|    3600.0|\n","+---+----------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.sql.functions import max\n","\n","# Group data by age and calculate the maximum salary for each age group\n","\n","employees_df.groupBy('age').agg(max(col('salary')).alias('Max_Salary')).show(5)\n"]},{"cell_type":"markdown","id":"2c2dd920-7096-412d-bd7c-98764847ffde","metadata":{},"source":["#### Self-Join on Employee Data\n","\n","Join the \"employees_df\" DataFrame with itself based on the \"Emp_No\" column. Display the result.\n"]},{"cell_type":"code","execution_count":25,"id":"ec9c5936-9874-4123-8196-e20182dc0583","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+---------+-------+---+----------+----------------+---------+-------+---+----------+----------------+\n","|Emp_No| Emp_Name| Salary|Age|Department|SalaryAfterBonus| Emp_Name| Salary|Age|Department|SalaryAfterBonus|\n","+------+---------+-------+---+----------+----------------+---------+-------+---+----------+----------------+\n","|   198|   Donald| 2600.0| 29|        IT|          2860.0|   Donald| 2600.0| 29|        IT|          2860.0|\n","|   199|  Douglas| 2600.0| 34|     Sales|          2860.0|  Douglas| 2600.0| 34|     Sales|          2860.0|\n","|   200| Jennifer| 4400.0| 36| Marketing|          4840.0| Jennifer| 4400.0| 36| Marketing|          4840.0|\n","|   201|  Michael|13000.0| 32|        IT|         14300.0|  Michael|13000.0| 32|        IT|         14300.0|\n","|   202|      Pat| 6000.0| 39|        HR|          6600.0|      Pat| 6000.0| 39|        HR|          6600.0|\n","|   203|    Susan| 6500.0| 36| Marketing|          7150.0|    Susan| 6500.0| 36| Marketing|          7150.0|\n","|   204|  Hermann|10000.0| 29|   Finance|         11000.0|  Hermann|10000.0| 29|   Finance|         11000.0|\n","|   205|  Shelley|12008.0| 33|   Finance|         13208.8|  Shelley|12008.0| 33|   Finance|         13208.8|\n","|   206|  William| 8300.0| 37|        IT|          9130.0|  William| 8300.0| 37|        IT|          9130.0|\n","|   100|   Steven|24000.0| 39|        IT|         26400.0|   Steven|24000.0| 39|        IT|         26400.0|\n","|   101|    Neena|17000.0| 27|     Sales|         18700.0|    Neena|17000.0| 27|     Sales|         18700.0|\n","|   102|      Lex|17000.0| 37| Marketing|         18700.0|      Lex|17000.0| 37| Marketing|         18700.0|\n","|   103|Alexander| 9000.0| 39| Marketing|          9900.0|Alexander| 9000.0| 39| Marketing|          9900.0|\n","|   104|    Bruce| 6000.0| 38|        IT|          6600.0|    Bruce| 6000.0| 38|        IT|          6600.0|\n","|   105|    David| 4800.0| 39|        IT|          5280.0|    David| 4800.0| 39|        IT|          5280.0|\n","|   106|    Valli| 4800.0| 38|     Sales|          5280.0|    Valli| 4800.0| 38|     Sales|          5280.0|\n","|   107|    Diana| 4200.0| 35|     Sales|          4620.0|    Diana| 4200.0| 35|     Sales|          4620.0|\n","|   108|    Nancy|12008.0| 28|     Sales|         13208.8|    Nancy|12008.0| 28|     Sales|         13208.8|\n","|   109|   Daniel| 9000.0| 35|        HR|          9900.0|   Daniel| 9000.0| 35|        HR|          9900.0|\n","|   110|     John| 8200.0| 31| Marketing|          9020.0|     John| 8200.0| 31| Marketing|          9020.0|\n","+------+---------+-------+---+----------+----------------+---------+-------+---+----------+----------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Join the DataFrame with itself based on the \"Emp_No\" column\n","employees_df.join(employees_df,on='Emp_No').show()"]},{"cell_type":"markdown","id":"12511ad1-d67f-4e40-9884-112da55491d7","metadata":{},"source":["#### Calculate Average Employee Age\n","\n","Calculate the average age of employees using the built-in aggregation function. Display the result.\n"]},{"cell_type":"code","execution_count":26,"id":"a084e273-e756-4da4-bc5e-57f6532937f5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+\n","|avg_age|\n","+-------+\n","|  33.56|\n","+-------+\n","\n"]}],"source":["# Calculate the average age of employees\n","from pyspark.sql.functions import avg \n","\n","employees_df.agg(avg(col('age')).alias('avg_age')).show()"]},{"cell_type":"markdown","id":"a56c04c4-12c1-45b9-839e-0f79ce2bced2","metadata":{},"source":["#### Calculate Total Salary by Department\n","\n","Calculate the total salary for each department using the built-in aggregation function. Display the result.\n"]},{"cell_type":"code","execution_count":27,"id":"27fd4e96-3157-4112-98a2-95bb22c152ad","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+------------+\n","|Department|Total_Salary|\n","+----------+------------+\n","|     Sales|     71408.0|\n","|        HR|     46700.0|\n","|   Finance|     57308.0|\n","| Marketing|     59700.0|\n","|        IT|     74000.0|\n","+----------+------------+\n","\n"]}],"source":["# Calculate the total salary for each department. \n","from pyspark.sql.functions import sum \n","\n","employees_df.groupBy('Department').agg(sum(col('salary')).alias('Total_Salary')).show(5)"]},{"cell_type":"markdown","id":"8d9c9d95-106f-4ecf-8925-b5fd654bd48d","metadata":{},"source":["#### Sort Data by Age and Salary\n","\n","Apply a transformation to sort the DataFrame by age in ascending order and then by salary in descending order. Display the sorted DataFrame.\n"]},{"cell_type":"code","execution_count":35,"id":"69fb26a2-20a2-48b9-a87a-61af2d4f6fac","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+-----------+-------+---+----------+----------------+\n","|Emp_No|   Emp_Name| Salary|Age|Department|SalaryAfterBonus|\n","+------+-----------+-------+---+----------+----------------+\n","|   100|     Steven|24000.0| 39|        IT|         26400.0|\n","|   101|      Neena|17000.0| 27|     Sales|         18700.0|\n","|   102|        Lex|17000.0| 37| Marketing|         18700.0|\n","|   201|    Michael|13000.0| 32|        IT|         14300.0|\n","|   205|    Shelley|12008.0| 33|   Finance|         13208.8|\n","|   108|      Nancy|12008.0| 28|     Sales|         13208.8|\n","|   114|        Den|11000.0| 27|   Finance|         12100.0|\n","|   204|    Hermann|10000.0| 29|   Finance|         11000.0|\n","|   103|  Alexander| 9000.0| 39| Marketing|          9900.0|\n","|   109|     Daniel| 9000.0| 35|        HR|          9900.0|\n","|   206|    William| 8300.0| 37|        IT|          9130.0|\n","|   110|       John| 8200.0| 31| Marketing|          9020.0|\n","|   121|       Adam| 8200.0| 39|        HR|          9020.0|\n","|   120|    Matthew| 8000.0| 30|        HR|          8800.0|\n","|   122|      Payam| 7900.0| 36|   Finance|          8690.0|\n","|   112|Jose Manuel| 7800.0| 34|        HR|          8580.0|\n","|   111|     Ismael| 7700.0| 32|        IT|          8470.0|\n","|   113|       Luis| 6900.0| 34|     Sales|          7590.0|\n","|   203|      Susan| 6500.0| 36| Marketing|          7150.0|\n","|   123|     Shanta| 6500.0| 35|     Sales|          7150.0|\n","+------+-----------+-------+---+----------+----------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Sort the DataFrame by age in ascending order and then by salary in descending order\n","employees_df.sort(col('age'),ascending=True).sort(col('salary'),ascending=False).show()"]},{"cell_type":"markdown","id":"30e2e205-7b61-4308-aa3e-c16b3d3ac8a9","metadata":{},"source":["#### Count Employees in Each Department\n","\n","Calculate the number of employees in each department. Display the result.\n"]},{"cell_type":"code","execution_count":30,"id":"409ab156-0ee8-4bab-8e65-f694fda48ab1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+---------------+\n","|Department|Total_Employees|\n","+----------+---------------+\n","|     Sales|             13|\n","|        HR|              8|\n","|   Finance|             10|\n","| Marketing|              9|\n","|        IT|             10|\n","+----------+---------------+\n","\n"]}],"source":["from pyspark.sql.functions import count\n","\n","# Calculate the number of employees in each department\n","employees_df.groupBy('Department').agg(count(col('Emp_No')).alias('Total_Employees')).show(5)"]},{"cell_type":"markdown","id":"ea2eefd4-ffab-489b-b863-7db3e113855d","metadata":{},"source":["#### Filter Employees with the letter o in the Name\n","\n","Apply a filter to select records where the employee's name contains the letter `'o'`. Display the filtered DataFrame.\n"]},{"cell_type":"code","execution_count":32,"id":"96503181-fa32-48a7-b778-afbb9b5aaf31","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+-----------+------+---+----------+----------------+\n","|Emp_No|   Emp_Name|Salary|Age|Department|SalaryAfterBonus|\n","+------+-----------+------+---+----------+----------------+\n","|   198|     Donald|2600.0| 29|        IT|          2860.0|\n","|   199|    Douglas|2600.0| 34|     Sales|          2860.0|\n","|   110|       John|8200.0| 31| Marketing|          9020.0|\n","|   112|Jose Manuel|7800.0| 34|        HR|          8580.0|\n","|   130|      Mozhe|2800.0| 28| Marketing|          3080.0|\n","|   133|      Jason|3300.0| 38|     Sales|          3630.0|\n","|   139|       John|2700.0| 36|     Sales|          2970.0|\n","|   140|     Joshua|2500.0| 29|   Finance|          2750.0|\n","+------+-----------+------+---+----------+----------------+\n","\n"]}],"source":["# Apply a filter to select records where the employee's name contains the letter 'o'\n","employees_df.filter(col('Emp_Name').contains('o')).show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
